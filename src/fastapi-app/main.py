"""
TFM Chocolate Factory - FastAPI Main Application
=================================================

El Cerebro Autónomo: FastAPI + APScheduler para automatización completa
- Endpoints: /predict y /ingest-now
- Automatización: APScheduler para ingestión y predicciones periódicas
- Simulación: SimPy/SciPy para lógica de fábrica
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from pydantic import BaseModel

from services.scheduler import get_scheduler_service, start_scheduler, stop_scheduler
from services.data_ingestion import DataIngestionService, run_current_ingestion, run_daily_ingestion
from services.ree_client import REEClient

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestión del ciclo de vida de la aplicación"""
    logger.info("🧠 Iniciando El Cerebro Autónomo - Chocolate Factory Brain")
    
    try:
        # Iniciar el scheduler automático
        await start_scheduler()
        logger.info("📅 APScheduler: Iniciado correctamente")
        logger.info("🏭 SimPy: Simulación pendiente")
        
        yield
        
    finally:
        # Detener el scheduler al cerrar la aplicación
        logger.info("🛑 Deteniendo El Cerebro Autónomo")
        await stop_scheduler()
        logger.info("📅 APScheduler: Detenido")


# Crear la aplicación FastAPI
app = FastAPI(
    title="TFM Chocolate Factory - El Cerebro Autónomo",
    description="Sistema autónomo de ingestión, predicción y monitoreo para fábrica de chocolate",
    version="0.1.0",
    lifespan=lifespan
)

# Configurar CORS para Node-RED dashboard
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producción, especificar dominios
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic para requests
class IngestionRequest(BaseModel):
    source: str = "ree"  # ree, aemet, all
    date_start: Optional[str] = None
    date_end: Optional[str] = None
    force_refresh: bool = False

class SchedulerJobRequest(BaseModel):
    job_id: str
    action: str  # trigger, pause, resume


@app.get("/")
async def root():
    """Endpoint raíz - Estado del sistema"""
    return {
        "service": "TFM Chocolate Factory Brain",
        "status": "🧠 El Cerebro Autónomo está funcionando",
        "version": "0.1.0",
        "endpoints": {
            "health": "/health",
            "predict": "/predict (pendiente)",
            "ingest": "/ingest-now",
            "scheduler": "/scheduler/status",
            "ree_prices": "/ree/prices",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """Health check para Docker"""
    return {
        "status": "healthy",
        "service": "chocolate_factory_brain",
        "message": "🧠 Sistema operativo"
    }


@app.get("/predict")
async def predict():
    """Endpoint de predicción ML (pendiente implementación)"""
    return {
        "status": "pending",
        "message": "🔮 Funcionalidad de predicción pendiente",
        "ml_models": "MLflow integration pending"
    }


@app.post("/ingest-now")
async def ingest_now(request: IngestionRequest, background_tasks: BackgroundTasks):
    """Forzar ingestión inmediata de datos"""
    try:
        logger.info(f"Manual ingestion requested for source: {request.source}")
        
        if request.source in ["ree", "all"]:
            # Ejecutar en background para no bloquear la respuesta
            background_tasks.add_task(run_current_ingestion)
            
            return {
                "status": "started",
                "message": "📥 Ingestión REE iniciada en background",
                "source": request.source,
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=400, detail=f"Unsupported source: {request.source}")
            
    except Exception as e:
        logger.error(f"Manual ingestion failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# Nuevos endpoints para REE y scheduler
@app.get("/ree/prices")
async def get_ree_prices(hours: int = 24):
    """Obtener precios REE de las próximas N horas"""
    try:
        async with REEClient() as client:
            if hours == 1:
                current_price = await client.get_current_price()
                return {
                    "status": "success",
                    "data": [current_price.dict()] if current_price else [],
                    "hours_requested": hours
                }
            else:
                prices = await client.get_price_forecast_24h()
                limited_prices = prices[:hours] if prices else []
                return {
                    "status": "success", 
                    "data": [price.dict() for price in limited_prices],
                    "hours_requested": hours,
                    "records_returned": len(limited_prices)
                }
                
    except Exception as e:
        logger.error(f"Failed to fetch REE prices: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/scheduler/status")
async def get_scheduler_status():
    """Obtener estado del scheduler y trabajos programados"""
    try:
        scheduler = await get_scheduler_service()
        status = scheduler.get_job_status()
        return {
            "status": "success",
            "scheduler": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get scheduler status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/job")
async def manage_scheduler_job(request: SchedulerJobRequest):
    """Gestionar trabajos del scheduler (trigger, pause, resume)"""
    try:
        scheduler = await get_scheduler_service()
        
        if request.action == "trigger":
            success = await scheduler.trigger_job_now(request.job_id)
        elif request.action == "pause":
            success = await scheduler.pause_job(request.job_id)
        elif request.action == "resume":
            success = await scheduler.resume_job(request.job_id)
        else:
            raise HTTPException(status_code=400, detail=f"Invalid action: {request.action}")
        
        if success:
            return {
                "status": "success",
                "message": f"Job {request.job_id} {request.action} completed",
                "job_id": request.job_id,
                "action": request.action
            }
        else:
            raise HTTPException(status_code=400, detail=f"Failed to {request.action} job {request.job_id}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to manage scheduler job: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/ingestion/status")
async def get_ingestion_status():
    """Obtener estado de la ingestion de datos"""
    try:
        async with DataIngestionService() as service:
            status = await service.get_ingestion_status()
        
        return {
            "status": "success",
            "ingestion": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get ingestion status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

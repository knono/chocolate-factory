"""
TFM Chocolate Factory - FastAPI Main Application
=================================================

El Cerebro Aut贸nomo: FastAPI + APScheduler para automatizaci贸n completa
- Endpoints: /predict y /ingest-now
- Automatizaci贸n: APScheduler para ingesti贸n y predicciones peri贸dicas
- Simulaci贸n: SimPy/SciPy para l贸gica de f谩brica
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from pydantic import BaseModel

from services.scheduler import get_scheduler_service, start_scheduler, stop_scheduler
from services.data_ingestion import DataIngestionService, run_current_ingestion, run_daily_ingestion
from services.ree_client import REEClient

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gesti贸n del ciclo de vida de la aplicaci贸n"""
    logger.info(" Iniciando El Cerebro Aut贸nomo - Chocolate Factory Brain")
    
    try:
        # Iniciar el scheduler autom谩tico
        await start_scheduler()
        logger.info(" APScheduler: Iniciado correctamente")
        logger.info(" SimPy: Simulaci贸n pendiente")
        
        yield
        
    finally:
        # Detener el scheduler al cerrar la aplicaci贸n
        logger.info(" Deteniendo El Cerebro Aut贸nomo")
        await stop_scheduler()
        logger.info(" APScheduler: Detenido")


# Crear la aplicaci贸n FastAPI
app = FastAPI(
    title="TFM Chocolate Factory - El Cerebro Aut贸nomo",
    description="Sistema aut贸nomo de ingesti贸n, predicci贸n y monitoreo para f谩brica de chocolate",
    version="0.1.0",
    lifespan=lifespan
)

# Configurar CORS para Node-RED dashboard
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci贸n, especificar dominios
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic para requests
class IngestionRequest(BaseModel):
    source: str = "ree"  # ree, aemet, all
    date_start: Optional[str] = None
    date_end: Optional[str] = None
    force_refresh: bool = False

class SchedulerJobRequest(BaseModel):
    job_id: str
    action: str  # trigger, pause, resume


@app.get("/")
async def root():
    """Endpoint ra铆z - Estado del sistema"""
    return {
        "service": "TFM Chocolate Factory Brain",
        "status": " El Cerebro Aut贸nomo est谩 funcionando",
        "version": "0.1.0",
        "endpoints": {
            "health": "/health",
            "predict": "/predict (pendiente)",
            "ingest": "/ingest-now",
            "scheduler": "/scheduler/status",
            "ree_prices": "/ree/prices",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """Health check para Docker"""
    return {
        "status": "healthy",
        "service": "chocolate_factory_brain",
        "message": " Sistema operativo"
    }


@app.get("/predict")
async def predict():
    """Endpoint de predicci贸n ML (pendiente implementaci贸n)"""
    return {
        "status": "pending",
        "message": " Funcionalidad de predicci贸n pendiente",
        "ml_models": "MLflow integration pending"
    }


@app.post("/ingest-now")
async def ingest_now(request: IngestionRequest, background_tasks: BackgroundTasks):
    """Forzar ingesti贸n inmediata de datos"""
    try:
        logger.info(f"Manual ingestion requested for source: {request.source}")
        
        if request.source in ["ree", "all"]:
            # Ejecutar en background para no bloquear la respuesta
            background_tasks.add_task(run_current_ingestion)
            
            return {
                "status": "started",
                "message": " Ingesti贸n REE iniciada en background",
                "source": request.source,
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=400, detail=f"Unsupported source: {request.source}")
            
    except Exception as e:
        logger.error(f"Manual ingestion failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# Nuevos endpoints para REE y scheduler
@app.get("/ree/prices")
async def get_ree_prices(hours: int = 24):
    """Obtener precios REE de las pr贸ximas N horas"""
    try:
        async with REEClient() as client:
            if hours == 1:
                current_price = await client.get_current_price()
                return {
                    "status": "success",
                    "data": [current_price.dict()] if current_price else [],
                    "hours_requested": hours
                }
            else:
                prices = await client.get_price_forecast_24h()
                limited_prices = prices[:hours] if prices else []
                return {
                    "status": "success", 
                    "data": [price.dict() for price in limited_prices],
                    "hours_requested": hours,
                    "records_returned": len(limited_prices)
                }
                
    except Exception as e:
        logger.error(f"Failed to fetch REE prices: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/scheduler/status")
async def get_scheduler_status():
    """Obtener estado del scheduler y trabajos programados"""
    try:
        scheduler = await get_scheduler_service()
        status = scheduler.get_job_status()
        return {
            "status": "success",
            "scheduler": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get scheduler status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/job")
async def manage_scheduler_job(request: SchedulerJobRequest):
    """Gestionar trabajos del scheduler (trigger, pause, resume)"""
    try:
        scheduler = await get_scheduler_service()
        
        if request.action == "trigger":
            success = await scheduler.trigger_job_now(request.job_id)
        elif request.action == "pause":
            success = await scheduler.pause_job(request.job_id)
        elif request.action == "resume":
            success = await scheduler.resume_job(request.job_id)
        else:
            raise HTTPException(status_code=400, detail=f"Invalid action: {request.action}")
        
        if success:
            return {
                "status": "success",
                "message": f"Job {request.job_id} {request.action} completed",
                "job_id": request.job_id,
                "action": request.action
            }
        else:
            raise HTTPException(status_code=400, detail=f"Failed to {request.action} job {request.job_id}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to manage scheduler job: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/ingestion/status")
async def get_ingestion_status():
    """Obtener estado de la ingestion de datos"""
    try:
        async with DataIngestionService() as service:
            status = await service.get_ingestion_status()
        
        return {
            "status": "success",
            "ingestion": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get ingestion status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

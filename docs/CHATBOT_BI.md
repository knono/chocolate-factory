# ğŸ¤– Chatbot BI - GuÃ­a Completa

> **Sprint 11**: Chatbot conversacional con Claude Haiku API para consultas BI en lenguaje natural.

**Estado**: âœ… **COMPLETADO** (Octubre 10, 2025)

---

## ğŸ“‹ Tabla de Contenidos

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Arquitectura](#arquitectura)
3. [Setup y ConfiguraciÃ³n](#setup-y-configuraciÃ³n)
4. [Uso del Chatbot](#uso-del-chatbot)
5. [API Reference](#api-reference)
6. [Optimizaciones](#optimizaciones)
7. [Costos y MÃ©tricas](#costos-y-mÃ©tricas)
8. [Troubleshooting](#troubleshooting)

---

## Resumen Ejecutivo

### Â¿QuÃ© es?

Sistema de chatbot conversacional que permite consultas en lenguaje natural sobre:
- âš¡ Precios energÃ©ticos (REE)
- ğŸ­ Ventanas Ã³ptimas de producciÃ³n
- ğŸ’° Ahorros energÃ©ticos
- ğŸŒ¡ï¸ Clima y condiciones
- ğŸ“Š Estado del sistema

### Â¿Por QuÃ© Chatbot en lugar de MCP?

| Requisito Usuario | MCP Server | Chatbot BI | Elegido |
|---|---|---|---|
| Acceso mÃ³vil | âŒ Solo desktop | âœ… Universal | âœ… Chatbot |
| Sin Claude Desktop | âŒ Requerido | âœ… Standalone | âœ… Chatbot |
| Multi-usuario | âŒ 1 usuario | âœ… Ilimitado | âœ… Chatbot |
| Costo mensual | â‚¬0 | ~â‚¬1.50-3 | âœ… Chatbot |
| AutonomÃ­a | âŒ Requiere Claude Code | âœ… 100% autÃ³nomo | âœ… Chatbot |

### CaracterÃ­sticas Clave

- âœ… **Claude Haiku 4.5**: Respuestas ultra-rÃ¡pidas y econÃ³micas (~8s latencia, 4-5x mÃ¡s rÃ¡pido)
- âœ… **Extended Thinking**: Capacidad de razonamiento mejorado (nueva en 4.5)
- âœ… **RAG Local**: Keyword matching inteligente (sin vector DB)
- âœ… **Llamadas Paralelas**: asyncio.gather() para reducir latencia 80%
- âœ… **Context Optimizado**: ~600-1200 tokens/pregunta (vs 5000 mal diseÃ±ado)
- âœ… **Integrado en Dashboard**: Widget de chatbot en `/static/index.html`
- âœ… **Rate Limiting**: 20 requests/minuto (protecciÃ³n costos)

---

## Arquitectura

### Stack TÃ©cnico

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Usuario (Dashboard Web)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP POST /chat/ask
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      api/routers/chatbot.py              â”‚
â”‚   - Rate limiting (20/min)               â”‚
â”‚   - Request validation                   â”‚
â”‚   - Stats tracking                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   services/chatbot_service.py            â”‚
â”‚   - Claude Haiku API client              â”‚
â”‚   - System prompt especializado          â”‚
â”‚   - Cost tracking                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ services/chatbot_context_service.py      â”‚
â”‚   - Keyword detection                    â”‚
â”‚   - Parallel HTTP calls (asyncio.gather)â”‚
â”‚   - Context building (~600-1200 tokens)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Llamadas PARALELAS a:
          â”œâ”€â†’ /dashboard/complete
          â”œâ”€â†’ /insights/optimal-windows
          â”œâ”€â†’ /ree/prices/latest
          â”œâ”€â†’ /ree/prices/stats
          â”œâ”€â†’ /insights/alerts
          â”œâ”€â†’ /insights/savings-tracking
          â””â”€â†’ /optimize/production/daily
```

### Flujo de Datos

```mermaid
sequenceDiagram
    participant U as Usuario
    participant R as chatbot_router
    participant S as chatbot_service
    participant C as context_service
    participant E as Endpoints API
    participant H as Claude Haiku

    U->>R: POST /chat/ask {"question": "Â¿cuÃ¡ndo producir?"}
    R->>S: ask(question)
    S->>C: build_context(question)

    Note over C,E: Llamadas PARALELAS con asyncio.gather()
    par Parallel Requests
        C->>E: GET /dashboard/complete
        C->>E: GET /insights/optimal-windows
        C->>E: GET /ree/prices/latest
    end

    E-->>C: Responses (2-3s total)
    C-->>S: Context built (~800 tokens)

    S->>H: messages.create(context + question)
    H-->>S: Response (~8-10s)

    S-->>R: {answer, tokens, latency, cost}
    R-->>U: ChatResponse JSON
```

---

## Setup y ConfiguraciÃ³n

### 1. Obtener API Key de Anthropic

```bash
# 1. Ir a https://console.anthropic.com/
# 2. Crear cuenta (si no tienes)
# 3. "API Keys" â†’ "Create Key"
# 4. Copiar: sk-ant-api03-xxxxxxxxxxxxx
```

**CrÃ©dito inicial**: $5 USD gratis (~1,600 preguntas de prueba)

### 2. Configurar Variables de Entorno

**Archivo**: `.env`

```bash
# Sprint 11 - Chatbot BI (Claude Haiku 4.5 API)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxx

# Opcionales (usar defaults si no se especifican)
CHATBOT_MAX_TOKENS=300                    # Max tokens respuesta
CHATBOT_MODEL=claude-haiku-4-5           # Modelo Haiku 4.5
```

### 3. Instalar Dependencias

```bash
cd src/fastapi-app
pip install anthropic==0.40.0 slowapi==0.1.9
```

### 4. Verificar InstalaciÃ³n

```bash
# Health check del chatbot
curl http://localhost:8000/chat/health

# Respuesta esperada:
# {
#   "status": "healthy",
#   "model": "claude-haiku-4-5",
#   "max_tokens": 300,
#   "total_questions": 0
# }
```

---

## Uso del Chatbot

### Desde el Dashboard Web

1. Abrir dashboard: `http://localhost:8000/static/index.html`
2. Localizar el widget "ğŸ’¬ Chatbot BI" en la interfaz
3. Escribir pregunta en lenguaje natural
4. Presionar Enter o hacer clic en ğŸ“¤

### Ejemplos de Preguntas

#### 1. Ventanas de ProducciÃ³n

```
â“ "Â¿CuÃ¡ndo debo producir hoy?"

ğŸ¤– RESPUESTA:
âœ… PRODUCIR: 2025-10-10 Â· 00-07h (madrugada)
ğŸ’¡ MÃ¡ximo ahorro de 283.39 â‚¬ en ventana de precio ultra-bajo
ğŸ“Š Precio: -0.0042 â‚¬/kWh, temperatura Ã³ptima 22Â°C

â±ï¸ Latencia: ~10s
ğŸ’° Costo: $0.001
```

#### 2. Precios EnergÃ­a

```
â“ "Â¿CuÃ¡l es el precio actual de energÃ­a?"

ğŸ¤– RESPUESTA:
âœ… 0.14 â‚¬/kWh (precio actual de energÃ­a)
ğŸ’¡ Tendencia en caÃ­da, momento favorable para monitorear
ğŸ“Š Temperatura en 22.16Â°C (zona Ã³ptima para producciÃ³n)

â±ï¸ Latencia: ~11s
ğŸ’° Costo: $0.0008
```

#### 3. Alertas

```
â“ "Â¿Hay alertas activas?"

ğŸ¤– RESPUESTA:
âœ… SÃ, hay 2 alertas activas de producciÃ³n
ğŸ’¡ Alertas sugieren ventanas Ã³ptimas con precios muy bajos
ğŸ“Š PrÃ³ximas 3h: precios valle <0.10â‚¬/kWh

â±ï¸ Latencia: ~14s
ğŸ’° Costo: $0.0009
```

#### 4. Ahorros

```
â“ "Â¿CuÃ¡nto ahorramos esta semana?"

ğŸ¤– RESPUESTA:
ğŸ’° Ahorro semanal: 31.85 â‚¬
ğŸ“Š Comparativa:
  â€¢ Optimizado: 185.29 â‚¬
  â€¢ Baseline: 217.14 â‚¬
  â€¢ Ahorro: 14.7%
ğŸ¯ ROI anual estimado: 1,661 â‚¬

â±ï¸ Latencia: ~12s
ğŸ’° Costo: $0.001
```

#### 5. Estado General

```
â“ "Dame un resumen del estado actual"

ğŸ¤– RESPUESTA:
âœ… SISTEMA OPERATIVO al 85.2% eficiencia
ğŸ’¡ Temperatura: 22.16Â°C (ideal para chocolate)
ğŸ’¡ Precio: 0.14 â‚¬/kWh con tendencia bajista
ğŸš€ Mantener producciÃ³n en curso

â±ï¸ Latencia: ~11s
ğŸ’° Costo: $0.001
```

### Desde API (curl)

```bash
# POST request con JSON
curl -X POST http://localhost:8000/chat/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Â¿CuÃ¡ndo debo producir hoy?",
    "user_id": "mobile_user_001"
  }'

# Respuesta JSON:
{
  "answer": "âœ… PRODUCIR: 2025-10-10 Â· 00-07h...",
  "tokens": {
    "input": 1037,
    "output": 185,
    "total": 1222
  },
  "latency_ms": 11312,
  "cost_usd": 0.00157,
  "model": "claude-3-5-haiku-20241022",
  "success": true,
  "timestamp": "2025-10-10T18:48:00"
}
```

---

## API Reference

### POST /chat/ask

Endpoint principal del chatbot.

**Request**:
```json
{
  "question": "string (3-500 caracteres)",
  "user_id": "string (opcional)"
}
```

**Response**:
```json
{
  "answer": "string (respuesta del chatbot)",
  "tokens": {
    "input": "int",
    "output": "int",
    "total": "int"
  },
  "latency_ms": "int",
  "cost_usd": "float",
  "model": "string",
  "success": "boolean",
  "timestamp": "string (ISO 8601)"
}
```

**Rate Limit**: 20 requests/minuto por IP

**Errores**:
- `400`: Pregunta invÃ¡lida (muy corta/larga)
- `429`: Rate limit excedido
- `500`: Error interno (API Key invÃ¡lida, timeout, etc.)

---

### GET /chat/stats

EstadÃ­sticas de uso del chatbot.

**Response**:
```json
{
  "total_questions": 11,
  "total_tokens_input": 8950,
  "total_tokens_output": 1587,
  "total_cost_usd": 0.013508,
  "questions_today": 11,
  "last_reset": "2025-10-10"
}
```

**Nota**: Stats se resetean diariamente a las 00:00.

---

### GET /chat/health

Health check del servicio.

**Response**:
```json
{
  "status": "healthy",
  "model": "claude-3-5-haiku-20241022",
  "max_tokens": 300,
  "total_questions": 11
}
```

---

## Optimizaciones

### 1. Llamadas HTTP Paralelas (asyncio.gather)

**Antes** (secuencial):
```python
# âŒ 12-15 segundos
await self._get_current_status()      # 2s
await self._get_optimal_windows()     # 2s
await self._get_price_forecast()      # 3s
await self._get_alerts()              # 2s
await self._get_savings()             # 2s
await self._get_production_plan()     # 3s
# TOTAL: ~14s
```

**Ahora** (paralelo):
```python
# âœ… 2-3 segundos
tasks = [
    self._get_current_status(),
    self._get_optimal_windows(),
    self._get_price_forecast(),
    self._get_alerts(),
    self._get_savings(),
    self._get_production_plan(),
]
results = await asyncio.gather(*tasks, return_exceptions=True)
# TOTAL: ~3s (tiempo de la mÃ¡s lenta)
```

**Mejora**: **80% reducciÃ³n** en tiempo de llamadas HTTP

---

### 2. Context Optimizado por Keyword

**Keyword Detection**:
```python
keywords_map = {
    "optimal_windows": ["cuÃ¡ndo", "cuando", "producir", "ventana"],
    "price_forecast": ["precio", "energÃ­a", "costo", "kwh"],
    "alerts": ["alerta", "problema", "warning"],
    "savings": ["ahorro", "saving", "comparar", "roi"],
    "production_plan": ["plan", "planificar", "optimizar"],
    "analysis": ["anÃ¡lisis", "histÃ³rico", "siar"],
}
```

**Ventaja**: Solo carga contexto relevante, reduciendo tokens 3-5x

---

### 3. System Prompt Especializado

**Incluye contexto de negocio**:
- Temperaturas Ã³ptimas chocolate: 18-22Â°C
- Consumo energÃ©tico: 350 kWh/batch
- Periodos tarifarios: P1 (caro), P2 (medio), P3 (valle)
- Objetivo: Maximizar producciÃ³n en P3 y precios bajos

**Formato de respuesta estructurado**:
- âœ… RESPUESTA DIRECTA (quÃ© hacer)
- ğŸ’¡ RAZÃ“N (por quÃ©)
- ğŸ“Š DATOS CLAVE (nÃºmeros del contexto)

---

## Costos y MÃ©tricas

### Pricing Claude Haiku 4.5 (Octubre 2025)

- **Input**: $1.00 per 1M tokens (+25% vs Haiku 3.5)
- **Output**: $5.00 per 1M tokens (+25% vs Haiku 3.5)

**Beneficios adicionales**:
- 4-5x mÃ¡s rÃ¡pido que Sonnet 4
- Extended thinking capabilities
- 64K output tokens (vs limitado en 3.5)
- Computer use y context awareness

### Costo por Pregunta (Promedio)

```
Input tokens:  800 Ã— $1.00/1M = $0.00080
Output tokens: 150 Ã— $5.00/1M = $0.00075
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $0.00155 (~â‚¬0.0015 por pregunta)
```

### ProyecciÃ³n Mensual

**Escenario Normal** (50 preguntas/dÃ­a):
```
50 preguntas/dÃ­a Ã— 30 dÃ­as = 1,500 preguntas/mes

Input:  800 Ã— 1,500 = 1.2M tokens â†’ $1.20
Output: 150 Ã— 1,500 = 225k tokens â†’ $1.13
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $2.33/mes (~â‚¬2.17/mes)
```

**Escenario Intensivo** (150 preguntas/dÃ­a):
```
150 preguntas/dÃ­a Ã— 30 dÃ­as = 4,500 preguntas/mes

Input:  800 Ã— 4,500 = 3.6M tokens â†’ $3.60
Output: 150 Ã— 4,500 = 675k tokens â†’ $3.38
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $6.98/mes (~â‚¬6.52/mes)
```

**Incremento vs Haiku 3.5**: +25% costo, pero con mejoras sustanciales en velocidad y capacidades

### Ahorro vs Proyecto Mal DiseÃ±ado

Gracias a **Clean Architecture + Context Optimizado**:

| MÃ©trica | Proyecto Mal DiseÃ±ado | Este Proyecto (Haiku 4.5) | Ahorro |
|---------|----------------------|---------------------------|--------|
| Context tokens | 5,000 | 800 | 6.2x |
| Costo/pregunta | $0.010 | $0.0015 | 6.7x |
| Costo/mes (50q/dÃ­a) | â‚¬14.00 | â‚¬2.17 | 6.5x |

**Ahorro real**: ~â‚¬12/mes gracias a arquitectura optimizada

---

### MÃ©tricas de Rendimiento

**Suite de tests completa** (5 preguntas):

```
Total preguntas: 5
Exitosas: 5 âœ…
Fallidas: 0
Tasa de Ã©xito: 100%

Tokens promedio: ~850/pregunta
Latencia promedio: ~12s
Costo promedio: $0.0012/pregunta
```

**Breakdown de latencia**:
- Context building (HTTP paralelo): ~2-3s (20%)
- Claude API inference: ~8-10s (80%)
- **Total**: ~10-13s

---

## Troubleshooting

### Problema 1: Error 401 "Invalid API Key"

**SÃ­ntomas**:
```json
{
  "answer": "âŒ Error del servicio Claude...",
  "success": false
}
```

**SoluciÃ³n**:
```bash
# 1. Verificar .env
cat .env | grep ANTHROPIC_API_KEY

# 2. Verificar formato (debe empezar con sk-ant-api03-)
# 3. Regenerar key en https://console.anthropic.com/
# 4. Reiniciar contenedor
docker compose restart fastapi-app
```

---

### Problema 2: Latencia > 20 segundos

**SÃ­ntomas**: Timeout o respuestas muy lentas

**DiagnÃ³stico**:
```bash
# Ver logs del contenedor
docker compose logs fastapi-app | grep -i "chatbot\|context"

# Buscar: "Ejecutando X llamadas HTTP en paralelo"
```

**Soluciones**:
1. **Si NO dice "en paralelo"**: CÃ³digo no actualizado, reiniciar contenedor
2. **Si dice "en paralelo"**: Problema de red o endpoints lentos
3. **Verificar endpoints**:
```bash
curl -w "@%{time_total}s\n" http://localhost:8000/dashboard/complete
curl -w "@%{time_total}s\n" http://localhost:8000/insights/optimal-windows
```

---

### Problema 3: Rate Limit Excedido

**SÃ­ntomas**:
```json
{
  "detail": "Rate limit exceeded: 20 per 1 minute"
}
```

**SoluciÃ³n**:
```python
# Ajustar en api/routers/chatbot.py
@router.post("/ask")
@limiter.limit("50/minute")  # Aumentar a 50
async def ask_chatbot(...):
```

---

### Problema 4: Respuestas con "No tengo datos"

**SÃ­ntomas**: Chatbot dice que no tiene informaciÃ³n a pesar de que los endpoints funcionan

**DiagnÃ³stico**:
```bash
# Test directo del context service
curl -X POST http://localhost:8000/chat/ask \
  -d '{"question": "test"}' | jq '.tokens'

# Si tokens.input < 500: Contexto vacÃ­o
```

**Soluciones**:
1. **Verificar logs**: `docker compose logs fastapi-app | tail -50`
2. **Verificar endpoints**: Todos deben responder 200 OK
3. **Reiniciar contenedor**: `docker compose restart fastapi-app`

---

## Extensiones Futuras (Opcional)

### Fase 2: Optimizaciones Avanzadas

1. **Prompt Caching de Anthropic**: Reducir costos 50%
2. **Cache local**: Respuestas idÃ©nticas en <5 min = 0 latencia
3. **Voice input**: Speech-to-text (Web Speech API)
4. **Historial conversaciÃ³n**: Multi-turn context

### Fase 3: Integraciones

1. **Notificaciones Telegram/WhatsApp**: Push proactivo
2. **Report generation**: "Genera PDF anÃ¡lisis semanal"
3. **Actions execution**: "Ejecuta plan optimizado para maÃ±ana"
4. **Multi-idioma**: EspaÃ±ol, inglÃ©s, catalÃ¡n

---

## Referencias

- **Anthropic API Docs**: https://docs.anthropic.com/en/api/
- **Claude Haiku**: https://docs.anthropic.com/en/docs/about-claude/models
- **Prompt Caching**: https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching
- **Sprint 11 Spec**: `.claude/sprints/infrastructure/SPRINT_11_CHATBOT_BI.md`

---

**VersiÃ³n**: 1.1 (Migrated to Haiku 4.5)
**Fecha actualizaciÃ³n**: 2025-10-17
**Autor**: Sprint 11 - Chatbot BI Team
**Estado**: âœ… ProducciÃ³n (Haiku 4.5)

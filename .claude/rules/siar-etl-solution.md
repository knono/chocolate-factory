# REGLA: Soluci√≥n ETL para Datos Hist√≥ricos SIAR

## CU√ÅNDO APLICAR ESTA REGLA

Esta regla se aplica cuando:
- Se necesitan datos hist√≥ricos meteorol√≥gicos para entrenamiento ML
- Los archivos CSV del sistema SIAR est√°n disponibles en `/data/hist√≥ricoClimaLinares/`
- Se requiere procesar datos hist√≥ricos de 25+ a√±os (2000-2025)
- Los datos actuales de AEMET/OpenWeatherMap son insuficientes para ML training

## CONTEXTO T√âCNICO

### Fuente de Datos: Sistema SIAR
- **Sistema**: Sistema de Informaci√≥n Agroclim√°tica para el Regad√≠o
- **URL oficial**: https://servicio.mapa.gob.es/websiar/SeleccionParametrosMap.aspx?dst=1
- **Formato**: CSV con separadores semicolon (;) y decimales con coma (,)
- **Ubicaci√≥n**: Linares (Ja√©n), Espa√±a
- **Cobertura**: 26 archivos CSV (2000-2025)

### Arquitectura de Datos
```
üìä Buckets InfluxDB:
‚îú‚îÄ‚îÄ energy_data (datos actuales)
‚îÇ   ‚îú‚îÄ‚îÄ REE + Weather streaming
‚îî‚îÄ‚îÄ siar_historical (datos hist√≥ricos)
    ‚îú‚îÄ‚îÄ SIAR_J09_Linares (2000-2017)
    ‚îî‚îÄ‚îÄ SIAR_J17_Linares (2018-2025)
```

## PROBLEMAS T√âCNICOS CONOCIDOS Y SOLUCIONES

### 1. UNICODE Y ESPACIOS ESPECIALES
**Problema**: CSV contienen espacios Unicode invisibles que rompen parsing
```
‚ùå Original: ' 2 8 / 1 2 / 2 0 0 9 ' (21 caracteres)
‚úÖ Esperado: '28/12/2009' (10 caracteres)
```

**Soluci√≥n Obligatoria**: Limpieza car√°cter por car√°cter
```python
def clean_line(line):
    clean_chars = []
    for char in line:
        if char.isprintable() and (char.isalnum() or char in ';,/:.-'):
            clean_chars.append(char)
    return ''.join(clean_chars)
```

### 2. FORMATO ESPA√ëOL DE DATOS
**Desaf√≠os**:
- Fechas: DD/MM/YYYY (formato espa√±ol)
- Decimales: coma (,) en lugar de punto (.)
- Separadores CSV: semicolon (;) en lugar de coma

**Soluciones Obligatorias**:
```python
# Decimales espa√±oles
def safe_float(value):
    return float(str(value).replace(',', '.'))

# Fechas espa√±olas
date_obj = pd.to_datetime(fecha_str, format='%d/%m/%Y')

# Separadores CSV
parts = clean_line.split(';')
```

### 3. DETECCI√ìN DE ESTACIONES
**Regla**: Detectar autom√°ticamente tipo de estaci√≥n por filename
```python
station_type = "J17" if "J17" in csv_file else "J09"
station_id = f"SIAR_{station_type}_Linares"
```

## IMPLEMENTACI√ìN OBLIGATORIA

### Script de Referencia
**Ubicaci√≥n**: `/scripts/test_siar_simple.py`
**Configuraci√≥n Obligatoria**:
```python
INFLUX_URL = "http://chocolate_factory_storage:8086"
INFLUX_TOKEN = "<your_influxdb_token_here>"  # Ver regla security-sensitive-data.md
INFLUX_ORG = "chocolate_factory"
BUCKET_NAME = "siar_historical"  # Bucket dedicado separado
```

### Proceso ETL Obligatorio
1. **Detecci√≥n de archivos**: `find /app/data -name '*.csv' -type 'f'`
2. **Detecci√≥n de encoding**: Probar latin-1, iso-8859-1, cp1252, utf-8
3. **Limpieza Unicode**: Aplicar `clean_line()` obligatoriamente
4. **Parsing datos**: Usar formatos espa√±oles
5. **Escritura por lotes**: 100 registros por batch a InfluxDB
6. **Tags obligatorios**: `data_source=siar_historical`, `station_id=SIAR_*`

### Ejecuci√≥n
```bash
# Dentro del contenedor
docker exec chocolate_factory_brain python /app/scripts/test_siar_simple.py
```

## VERIFICACI√ìN OBLIGATORIA

### Resultados Esperados
- **Total archivos**: 26 CSV procesados (100% √©xito)
- **Total registros**: ~88,935 registros en InfluxDB
- **Estaciones**: SIAR_J09_Linares + SIAR_J17_Linares
- **Tiempo**: ~3 minutos para 25+ a√±os de datos

### Comandos de Verificaci√≥n
```bash
# Verificar carga por estaci√≥n
docker exec chocolate_factory_storage influx query '
from(bucket: "siar_historical")
|> range(start: 2000-01-01T00:00:00Z, stop: 2025-12-31T23:59:59Z)
|> group(columns: ["station_id"])
|> count()'

# Verificar rango temporal
docker exec chocolate_factory_storage influx query '
from(bucket: "siar_historical")
|> range(start: 2000-01-01T00:00:00Z, stop: 2025-12-31T23:59:59Z)
|> first() |> yield(name: "first_record")
from(bucket: "siar_historical")
|> range(start: 2000-01-01T00:00:00Z, stop: 2025-12-31T23:59:59Z)
|> last() |> yield(name: "last_record")'
```

### Resultado Correcto Esperado
```
SIAR_J09_Linares: 62,842 records (2000-2017)
SIAR_J17_Linares: 26,093 records (2018-2025)
Total: 88,935 registros hist√≥ricos
```

## ERRORES COMUNES Y SOLUCIONES

### Error: "unauthorized access"
**Causa**: Token InfluxDB incorrecto
**Soluci√≥n**: Verificar token con `docker exec chocolate_factory_storage influx auth list`

### Error: "Failed to establish connection"
**Causa**: URL InfluxDB incorrecta desde contenedor
**Soluci√≥n**: Usar `http://chocolate_factory_storage:8086` (NO localhost)

### Error: Parsing de fechas falla
**Causa**: Espacios Unicode no limpiados
**Soluci√≥n**: Aplicar obligatoriamente funci√≥n `clean_line()`

### Error: Archivo no encontrado
**Causa**: Bind mount no configurado
**Soluci√≥n**: Verificar `./data:/app/data` en docker-compose.yml

## BENEFICIOS GARANTIZADOS

### Para ML Training
- **25+ a√±os** de datos hist√≥ricos meteorol√≥gicos
- **Datos oficiales** del gobierno espa√±ol (SIAR)
- **Separaci√≥n clara** entre hist√≥rico y tiempo real
- **Trazabilidad completa** con tags descriptivos

### Para Sistema
- **Bucket dedicado**: No contamina datos actuales
- **Rendimiento**: 3 minutos para 25 a√±os
- **Robustez**: Maneja errores y contin√∫a procesando
- **Persistencia**: Datos sobreviven reinicios del sistema

## INTEGRACI√ìN CON ML

### Uso en Modelos
```python
# Para training con datos hist√≥ricos
bucket = "siar_historical"
filter = 'r.data_source == "siar_historical"'

# Para predicci√≥n en tiempo real
bucket = "energy_data"
filter = 'r.data_source =~ /aemet|openweather/'
```

### Features Disponibles (10 campos)
1. `temperature` - Temperatura media
2. `temperature_max` - Temperatura m√°xima
3. `temperature_min` - Temperatura m√≠nima
4. `humidity` - Humedad media
5. `humidity_max` - Humedad m√°xima
6. `humidity_min` - Humedad m√≠nima
7. `wind_speed` - Velocidad del viento
8. `wind_direction` - Direcci√≥n del viento
9. `wind_gust` - R√°faga m√°xima
10. `precipitation` - Precipitaci√≥n

## REGLAS DE MANTENIMIENTO

### NO Hacer
- ‚ùå No usar el bucket `energy_data` para datos SIAR
- ‚ùå No usar localhost como URL InfluxDB desde contenedor
- ‚ùå No procesar archivos sin limpieza Unicode
- ‚ùå No usar formatos de fecha no espa√±oles
- ‚ùå No copiar archivos al contenedor (usar bind mount)

### S√ç Hacer
- ‚úÖ Usar bucket dedicado `siar_historical`
- ‚úÖ Aplicar limpieza Unicode obligatoriamente
- ‚úÖ Usar formatos espa√±oles (DD/MM/YYYY, coma decimal)
- ‚úÖ Verificar resultados con queries InfluxDB
- ‚úÖ Separar claramente hist√≥rico de tiempo real

## CUANDO APLICAR ESTA REGLA

**Aplica cuando**:
- Usuario solicita datos hist√≥ricos meteorol√≥gicos
- Se necesita entrenar modelos ML con m√°s datos
- Los datos actuales son insuficientes (< 1000 registros)
- Se quiere a√±adir robustez al sistema ML

**No aplica cuando**:
- Solo se necesitan datos actuales
- El bucket `siar_historical` ya contiene 88,935 registros
- Se trabaja con datos de otras ubicaciones geogr√°ficas
- Se requieren datos meteorol√≥gicos en tiempo real

---

**√öLTIMA ACTUALIZACI√ìN**: Septiembre 2025 - Soluci√≥n verificada y funcional
**ESTADO**: ‚úÖ PROBADO Y FUNCIONANDO - 88,935 registros cargados exitosamente
# ğŸ¯ SPRINT 13: Tailscale Observability - Enfoque HÃ­brido

> **Estado**: ğŸ”´ NO INICIADO
> **Prioridad**: ğŸŸ¡ MEDIA
> **Prerequisito**: Sprint 11-12 completados, Tailscale sidecar operacional
> **DuraciÃ³n estimada**: 2-3 dÃ­as (12-16 horas)
> **Fecha inicio planeada**: 2025-10-21

---

## ğŸ“‹ Objetivo

**Implementar observabilidad Tailscale con enfoque hÃ­brido**: sistema prÃ¡ctico nativo 24/7 + MCP learning educacional.

### Â¿Por quÃ© Enfoque HÃ­brido?

**Problema**: Elegir entre utilidad prÃ¡ctica vs conocimiento MCP

**SoluciÃ³n**: Implementar ambos en fases
1. **Fase 1 (PrÃ¡ctico)**: Monitoring nativo + nginx logs â†’ Dashboard 24/7
2. **Fase 2 (Educacional)**: MCP Tailscale â†’ Aprender ecosistema MCP

**Resultado**: Observabilidad funcional + conocimiento MCP adquirido

---

## ğŸ“¦ Arquitectura Propuesta

### Stack Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fase 1: Sistema Nativo (PrÃ¡ctico)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Tailscale CLI                           â”‚
â”‚  â”œâ”€ tailscale status --json              â”‚
â”‚  â””â”€ tailscale whois <ip>                 â”‚
â”‚           â†“                              â”‚
â”‚  AnalyticsService                        â”‚
â”‚  â”œâ”€ Parse nginx logs                     â”‚
â”‚  â”œâ”€ Correlate w/ Tailscale CLI          â”‚
â”‚  â””â”€ Store InfluxDB                       â”‚
â”‚           â†“                              â”‚
â”‚  Dashboard Widget (24/7)                 â”‚
â”‚  â””â”€ Analytics Ãºltima semana              â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fase 2: MCP Learning (Educacional)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Tailscale MCP Server                    â”‚
â”‚  â”œâ”€ @tailscale/mcp-server                â”‚
â”‚  â””â”€ Requiere Claude Desktop              â”‚
â”‚           â†“                              â”‚
â”‚  Comparativa:                            â”‚
â”‚  â”œâ”€ MCP tools vs CLI nativo              â”‚
â”‚  â”œâ”€ Performance comparison               â”‚
â”‚  â””â”€ Documentar aprendizajes              â”‚
â”‚           â†“                              â”‚
â”‚  DecisiÃ³n Final:                         â”‚
â”‚  â””â”€ Quedarse con soluciÃ³n preferida      â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Fase 1: Sistema Nativo (Prioridad Alta)

### 1.1. Analytics Service

**Archivo**: `src/fastapi-app/services/tailscale_analytics_service.py`

```python
import subprocess
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any

class TailscaleAnalyticsService:
    """
    Observabilidad Tailscale usando comandos CLI nativos.
    No requiere API key, usa tailscale CLI ya instalado.
    """

    async def get_active_devices(self) -> List[Dict]:
        """
        Lista dispositivos conectados a la Tailnet.

        Command: tailscale status --json
        """
        result = subprocess.run(
            ["tailscale", "status", "--json"],
            capture_output=True,
            text=True
        )

        data = json.loads(result.stdout)
        devices = []

        for peer in data.get("Peer", {}).values():
            if peer.get("Online", False):
                devices.append({
                    "hostname": peer.get("HostName"),
                    "ip": peer.get("TailscaleIPs", [])[0],
                    "os": peer.get("OS"),
                    "online": True,
                    "last_seen": peer.get("LastSeen")
                })

        return devices

    async def whois_ip(self, ip: str) -> Dict[str, Any]:
        """
        Identifica usuario/dispositivo por IP.

        Command: tailscale whois <ip>
        """
        result = subprocess.run(
            ["tailscale", "whois", ip],
            capture_output=True,
            text=True
        )

        # Parse output (formato: hostname\nuser@example.com)
        lines = result.stdout.split('\n')
        return {
            "hostname": lines[0] if len(lines) > 0 else None,
            "user": lines[1] if len(lines) > 1 else None,
            "ip": ip
        }

    async def parse_nginx_logs(self, hours: int = 24) -> List[Dict]:
        """
        Parse nginx access.log del sidecar Tailscale.

        Log format: 100.x.x.x - - [08/Oct/2025:14:32:15] "GET /dashboard" 200
        """
        log_file = Path("/logs/sidecar/access.log")

        if not log_file.exists():
            return []

        cutoff = datetime.now() - timedelta(hours=hours)
        access_logs = []

        with open(log_file, 'r') as f:
            for line in f:
                parsed = self._parse_nginx_line(line)
                if parsed and parsed["timestamp"] > cutoff:
                    # Enrich con Tailscale whois
                    user_info = await self.whois_ip(parsed["ip"])
                    parsed["user"] = user_info.get("user")
                    parsed["device"] = user_info.get("hostname")
                    access_logs.append(parsed)

        return access_logs

    def _parse_nginx_line(self, line: str) -> Dict:
        """Parse single nginx log line."""
        # Regex pattern para nginx log format
        pattern = r'(\d+\.\d+\.\d+\.\d+) .* \[(.+?)\] "(\w+) (.+?) HTTP.*?" (\d+)'
        match = re.match(pattern, line)

        if match:
            ip, timestamp_str, method, endpoint, status = match.groups()
            return {
                "ip": ip,
                "timestamp": datetime.strptime(timestamp_str, "%d/%b/%Y:%H:%M:%S"),
                "method": method,
                "endpoint": endpoint,
                "status": int(status)
            }
        return None

    async def store_analytics(self, log: Dict):
        """Guarda analytics en InfluxDB para histÃ³ricos."""
        point = Point("tailscale_access") \
            .tag("user", log.get("user", "unknown")) \
            .tag("device", log.get("device", "unknown")) \
            .tag("endpoint", log["endpoint"]) \
            .field("status", log["status"]) \
            .time(log["timestamp"])

        await self.influx_client.write(point)
```

---

### 1.2. API Endpoints

**Archivo**: `src/fastapi-app/api/routers/analytics.py`

```python
from fastapi import APIRouter, Query
from services.tailscale_analytics_service import TailscaleAnalyticsService

router = APIRouter(prefix="/analytics", tags=["Analytics"])

@router.get("/devices")
async def get_active_devices():
    """
    Lista dispositivos activos en Tailnet.

    Uses: tailscale status --json
    """
    service = TailscaleAnalyticsService()
    devices = await service.get_active_devices()

    return {
        "devices": devices,
        "total": len(devices)
    }

@router.get("/access-logs")
async def get_access_logs(hours: int = Query(default=24, ge=1, le=168)):
    """
    Access logs Ãºltimas N horas con usuario Tailscale identificado.

    Uses: nginx logs + tailscale whois
    """
    service = TailscaleAnalyticsService()
    logs = await service.parse_nginx_logs(hours=hours)

    # Analytics summary
    unique_users = len(set(log["user"] for log in logs if log["user"]))
    unique_devices = len(set(log["device"] for log in logs if log["device"]))

    return {
        "logs": logs,
        "summary": {
            "total_requests": len(logs),
            "unique_users": unique_users,
            "unique_devices": unique_devices,
            "period_hours": hours
        }
    }

@router.get("/dashboard-usage")
async def get_dashboard_usage(days: int = Query(default=7, ge=1, le=30)):
    """
    MÃ©tricas de uso dashboard desde InfluxDB.

    Returns:
    - Most viewed endpoints
    - Peak hours
    - User sessions
    """
    # Query InfluxDB metrics
    query = f"""
    from(bucket: "analytics")
      |> range(start: -{days}d)
      |> filter(fn: (r) => r._measurement == "tailscale_access")
      |> group(columns: ["endpoint"])
      |> count()
    """

    # Process results...
    return {
        "most_viewed_endpoints": [...],
        "peak_hours": [...],
        "active_users": [...]
    }
```

---

### 1.3. Dashboard Widget

**Archivo**: `static/js/components/analytics-widget.js`

```javascript
async function renderAnalyticsWidget() {
    const response = await fetch('/analytics/access-logs?hours=168');
    const data = await response.json();

    const container = document.getElementById('analytics-widget');

    container.innerHTML = `
        <div class="card analytics-card">
            <h3>ğŸ“Š Analytics Ãšltima Semana</h3>

            <div class="metrics-grid">
                <div class="metric">
                    <span class="label">Accesos Totales:</span>
                    <span class="value">${data.summary.total_requests}</span>
                </div>

                <div class="metric">
                    <span class="label">Usuarios Ãšnicos:</span>
                    <span class="value">${data.summary.unique_users}</span>
                </div>

                <div class="metric">
                    <span class="label">Dispositivos:</span>
                    <span class="value">${data.summary.unique_devices}</span>
                </div>
            </div>

            <div class="recent-activity">
                <h4>Actividad Reciente:</h4>
                <ul>
                    ${data.logs.slice(0, 5).map(log => `
                        <li>
                            <strong>${log.user || 'Unknown'}</strong>
                            (${log.device || 'Unknown'})
                            â†’ ${log.endpoint}
                            <span class="timestamp">${formatTime(log.timestamp)}</span>
                        </li>
                    `).join('')}
                </ul>
            </div>
        </div>
    `;
}

// Refresh cada 5 minutos
setInterval(renderAnalyticsWidget, 300000);
```

**AÃ±adir a `static/index.html`**:
```html
<!-- Analytics Widget -->
<div id="analytics-widget"></div>
<script src="js/components/analytics-widget.js"></script>
```

---

### 1.4. APScheduler Job

**Archivo**: `src/fastapi-app/tasks/analytics_jobs.py`

```python
async def collect_analytics():
    """
    Job APScheduler: Recolectar analytics cada 15 minutos.

    - Parse nginx logs
    - Enrich con Tailscale CLI
    - Store InfluxDB
    """
    service = TailscaleAnalyticsService()
    logs = await service.parse_nginx_logs(hours=1)  # Ãšltima hora

    for log in logs:
        await service.store_analytics(log)

    logger.info(f"Analytics collected: {len(logs)} accesses")

# Registrar en scheduler_config.py
scheduler.add_job(
    collect_analytics,
    trigger="interval",
    minutes=15,
    id="analytics_collection",
    name="Tailscale Analytics Collection"
)
```

---

## ğŸ“ Fase 2: MCP Learning (Opcional Educacional)

### 2.1. InstalaciÃ³n Tailscale MCP

**Setup**:
```bash
# 1. Generar API key Tailscale
# https://login.tailscale.com/admin/settings/keys

# 2. AÃ±adir a .env
TAILSCALE_API_KEY=tskey-api-xxxxx
TAILNET=your-tailnet.ts.net

# 3. Configurar Claude Desktop
cat ~/.config/Claude/claude_desktop_config.json
```

**Config**:
```json
{
  "mcpServers": {
    "tailscale": {
      "command": "npx",
      "args": ["-y", "@tailscale/mcp-server"],
      "env": {
        "TAILSCALE_API_KEY": "${TAILSCALE_API_KEY}",
        "TAILNET": "${TAILNET}"
      }
    }
  }
}
```

---

### 2.2. Tools MCP Disponibles

**Nativos de @tailscale/mcp-server**:

1. **`tailscale_list_devices`**
   - Lista dispositivos Tailnet
   - Equivalente CLI: `tailscale status --json`

2. **`tailscale_get_device`**
   - Info detallada dispositivo
   - Equivalente CLI: `tailscale status <hostname>`

3. **`tailscale_whois`**
   - Identificar usuario por IP
   - Equivalente CLI: `tailscale whois <ip>`

4. **`tailscale_get_status`**
   - Estado conexiÃ³n Tailscale
   - Equivalente CLI: `tailscale status`

---

### 2.3. Ejercicio Comparativo

**Objetivo**: Comparar MCP vs CLI nativo

**Test 1: Listar dispositivos**
```bash
# CLI nativo
time tailscale status --json

# MCP (en Claude Code)
User: "Â¿QuÃ© dispositivos estÃ¡n en la Tailnet?"
Claude: [usa tailscale_list_devices]
# â†’ Medir latencia respuesta
```

**Test 2: Identificar usuario**
```bash
# CLI nativo
time tailscale whois 100.x.x.x

# MCP
User: "Â¿QuiÃ©n es 100.x.x.x?"
Claude: [usa tailscale_whois]
# â†’ Comparar resultados
```

**Documentar**:
```markdown
## Comparativa MCP vs CLI

| OperaciÃ³n | CLI Nativo | MCP Tailscale | Diferencia |
|-----------|------------|---------------|------------|
| List devices | 0.2s | 1.5s | +1.3s (overhead) |
| Whois IP | 0.1s | 1.2s | +1.1s |
| Accesibilidad | Terminal | Claude Code | MCP mÃ¡s natural |
| AutonomÃ­a | âœ… 24/7 | âŒ Solo con Claude Desktop | CLI mejor para automation |

**ConclusiÃ³n**:
- CLI nativo: Mejor para sistema autÃ³nomo 24/7
- MCP: Mejor para consultas ad-hoc conversacionales
```

---

## ğŸ“ Plan de ImplementaciÃ³n

### Fase 1: Sistema Nativo (8-10 horas) - PRIORIDAD

- [ ] **(2h)** Crear `services/tailscale_analytics_service.py`
  - [ ] Implementar `get_active_devices()` (CLI)
  - [ ] Implementar `whois_ip()` (CLI)
  - [ ] Implementar `parse_nginx_logs()`
  - [ ] Implementar `store_analytics()` (InfluxDB)

- [ ] **(2h)** Crear `api/routers/analytics.py`
  - [ ] Endpoint `GET /analytics/devices`
  - [ ] Endpoint `GET /analytics/access-logs`
  - [ ] Endpoint `GET /analytics/dashboard-usage`

- [ ] **(2h)** Dashboard widget
  - [ ] Crear `static/js/components/analytics-widget.js`
  - [ ] Integrar en `index.html`
  - [ ] CSS styling

- [ ] **(1h)** APScheduler job
  - [ ] Job `collect_analytics()` cada 15 min
  - [ ] Test recolecciÃ³n datos

- [ ] **(1h)** Nginx logs persistence
  - [ ] Bind mount: `./logs/sidecar:/var/log/nginx`
  - [ ] Test parseo logs

### Fase 2: MCP Learning (4-6 horas) - OPCIONAL

- [ ] **(1h)** Setup Tailscale MCP
  - [ ] Generar API key
  - [ ] Configurar `claude_desktop_config.json`
  - [ ] Test tools en Claude Code

- [ ] **(2h)** Ejercicio comparativo
  - [ ] Test 1: List devices (CLI vs MCP)
  - [ ] Test 2: Whois (CLI vs MCP)
  - [ ] Test 3: Latencia comparison
  - [ ] Documentar resultados

- [ ] **(1-2h)** DocumentaciÃ³n aprendizajes
  - [ ] `docs/MCP_TAILSCALE_LEARNING.md`
  - [ ] Pros/cons cada enfoque
  - [ ] RecomendaciÃ³n final

- [ ] **(opcional)** DecisiÃ³n mantener o remover MCP
  - Si Ãºtil: Mantener ambos
  - Si no: Documentar y remover MCP setup

---

## ğŸ§ª Criterios de Ã‰xito

### Fase 1 (Obligatorio)

- âœ… **3 endpoints analytics** operacionales
- âœ… **Dashboard widget** muestra datos reales
- âœ… **APScheduler job** recolecta cada 15 min
- âœ… **Nginx logs** persisten entre reinicios
- âœ… **InfluxDB** guarda histÃ³ricos analytics

### Fase 2 (Opcional)

- âœ… **Tailscale MCP** instalado y funcional
- âœ… **4 tools MCP** funcionan en Claude Code
- âœ… **Comparativa** documentada (CLI vs MCP)
- âœ… **DecisiÃ³n final** tomada y documentada

---

## ğŸ’° AnÃ¡lisis Comparativo

### Soluciones Disponibles

| SoluciÃ³n | Setup | RAM | AutonomÃ­a | IntegraciÃ³n Claude | Costo |
|----------|-------|-----|-----------|-------------------|-------|
| **Prometheus/Grafana** | 6-8h | +500MB | âœ… 24/7 | âŒ No | â‚¬0 |
| **Tailscale MCP** | 2h | +10MB | âŒ Solo con Claude Desktop | âœ… Nativo | â‚¬0 |
| **CLI Nativo (HÃ­brido)** | 4h | +5MB | âœ… 24/7 | âš ï¸ Indirecto (via API) | â‚¬0 |

**RecomendaciÃ³n**: CLI Nativo (Fase 1) + MCP Learning (Fase 2 opcional)

---

## ğŸš§ Problemas Potenciales

### Problema 1: Nginx logs no accesibles

**SÃ­ntomas**: Permission denied al leer `/logs/sidecar/access.log`

**SoluciÃ³n**:
```bash
# Crear directorio bind mount
mkdir -p ./logs/sidecar

# Ajustar permisos
chmod -R 755 ./logs/sidecar/

# Actualizar docker-compose.yml
volumes:
  - ./logs/sidecar:/var/log/nginx:rw
```

### Problema 2: Tailscale CLI no funciona en container

**SÃ­ntomas**: `tailscale: command not found`

**SoluciÃ³n**:
```dockerfile
# Dockerfile FastAPI
RUN curl -fsSL https://tailscale.com/install.sh | sh

# O ejecutar desde host
# y compartir socket /var/run/tailscale/tailscaled.sock
```

### Problema 3: MCP Tailscale requiere API key

**SÃ­ntomas**: "TAILSCALE_API_KEY not set"

**SoluciÃ³n**:
```bash
# 1. Generar key en Tailscale admin
https://login.tailscale.com/admin/settings/keys

# 2. AÃ±adir a .env
TAILSCALE_API_KEY=tskey-api-xxxxx

# 3. Verificar en config
cat ~/.config/Claude/claude_desktop_config.json | grep TAILSCALE
```

---

## ğŸ“Š Valor del Sprint 13

### Beneficios Inmediatos (Fase 1)

1. **Observabilidad 24/7**: Saber quiÃ©n usa el sistema
2. **Dashboard analytics**: MÃ©tricas visuales histÃ³ricas
3. **Autonomous monitoring**: APScheduler automÃ¡tico
4. **Zero dependencies**: Solo CLI nativo + nginx logs
5. **InfluxDB integration**: HistÃ³ricos para anÃ¡lisis

### Beneficios Educacionales (Fase 2)

1. **Aprender MCP externo**: Experiencia real con third-party MCP
2. **Comparativa prÃ¡ctica**: Entender trade-offs MCP vs nativo
3. **Conocimiento ecosistema**: PreparaciÃ³n para futuros MCPs
4. **DecisiÃ³n informada**: Elegir mejor soluciÃ³n basado en datos

---

## ğŸ“š Referencias

### Fase 1 (Nativo)
- **Tailscale CLI**: https://tailscale.com/kb/1080/cli
- **nginx logs**: http://nginx.org/en/docs/http/ngx_http_log_module.html
- **InfluxDB Python**: https://influxdb-client.readthedocs.io/

### Fase 2 (MCP)
- **Tailscale MCP**: https://github.com/tailscale/tailscale-mcp
- **MCP Specification**: https://spec.modelcontextprotocol.io/
- **Anthropic MCP**: https://docs.anthropic.com/en/docs/mcp

---

## ğŸ”„ PrÃ³ximos Pasos

**DespuÃ©s Fase 1**:
- Dashboard analytics operacional 24/7
- DecisiÃ³n: Â¿Continuar con Fase 2 MCP?

**DespuÃ©s Fase 2 (si se hace)**:
- Comparativa documentada
- Elegir mantener MCP o solo nativo
- Actualizar CLAUDE.md con decisiÃ³n

**Extensiones Futuras**:
- Alerting automÃ¡tico (Telegram/Discord)
- Exportar reports PDF mensuales
- A/B testing dashboard features

---

**Fecha creaciÃ³n**: 2025-10-10
**Autor**: Infrastructure Sprint Planning
**VersiÃ³n**: 2.0 (Enfoque HÃ­brido: Nativo + MCP Learning)
**Sprint anterior**: Sprint 12 - Forgejo CI/CD
**Mejora clave**: PrÃ¡ctico (24/7) + Educacional (MCP) en lugar de solo MCP

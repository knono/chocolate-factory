[
    {
        "id": "dashboard_tab",
        "type": "tab",
        "label": "üç´ Chocolate Factory Dashboard",
        "disabled": false,
        "info": "Main dashboard for TFM Chocolate Factory monitoring and optimization"
    },
    {
        "id": "dashboard_group_main",
        "type": "ui_group",
        "name": "üìä Real-time Metrics",
        "tab": "dashboard_tab",
        "order": 1,
        "disp": true,
        "width": "12",
        "collapse": false
    },
    {
        "id": "dashboard_group_charts",
        "type": "ui_group", 
        "name": "üìà Historical Trends",
        "tab": "dashboard_tab",
        "order": 2,
        "disp": true,
        "width": "12",
        "collapse": false
    },
    {
        "id": "dashboard_group_ml",
        "type": "ui_group",
        "name": "ü§ñ ML Predictions",
        "tab": "dashboard_tab",
        "order": 3,
        "disp": true,
        "width": "12", 
        "collapse": false
    },
    {
        "id": "dashboard_group_alerts",
        "type": "ui_group",
        "name": "üö® Production Alerts",
        "tab": "dashboard_tab",
        "order": 4,
        "disp": true,
        "width": "12",
        "collapse": false
    },
    {
        "id": "influx_query_prices",
        "type": "function",
        "z": "dashboard_tab",
        "name": "Query REE Prices",
        "func": "// Query InfluxDB for latest REE energy prices\nconst query = `\nfrom(bucket: \"chocolate_factory\")\n  |> range(start: -24h)\n  |> filter(fn: (r) => r._measurement == \"energy_prices\")\n  |> filter(fn: (r) => r._field == \"price_eur_kwh\")\n  |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)\n  |> yield(name: \"mean\")\n`;\n\nmsg.query = query;\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 200,
        "y": 100,
        "wires": [["influx_out_prices"]]
    },
    {
        "id": "influx_out_prices",
        "type": "influxdb out",
        "z": "dashboard_tab",
        "influxdb": "influx_config",
        "name": "InfluxDB Query",
        "measurement": "",
        "precision": "",
        "retentionPolicy": "",
        "database": "",
        "precisionV18FluxV20": "ms",
        "retentionPolicyV18Flux": "",
        "writeType": "query",
        "x": 400,
        "y": 100,
        "wires": [["process_prices"]]
    },
    {
        "id": "process_prices",
        "type": "function",
        "z": "dashboard_tab", 
        "name": "Process Price Data",
        "func": "// Process InfluxDB response for dashboard display\nif (msg.payload && Array.isArray(msg.payload)) {\n    const prices = msg.payload.map(record => ({\n        time: new Date(record._time),\n        price: parseFloat(record._value).toFixed(4),\n        timestamp: record._time\n    }));\n    \n    // Latest price for gauge\n    if (prices.length > 0) {\n        const latest = prices[prices.length - 1];\n        msg.currentPrice = {\n            payload: parseFloat(latest.price),\n            topic: \"current_price\"\n        };\n        \n        // Price trend for chart\n        msg.priceHistory = {\n            payload: prices,\n            topic: \"price_history\"\n        };\n        \n        return [msg.currentPrice, msg.priceHistory];\n    }\n}\n\nreturn null;",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 600,
        "y": 100,
        "wires": [["price_gauge"], ["price_chart"]]
    },
    {
        "id": "price_gauge",
        "type": "ui_gauge",
        "z": "dashboard_tab",
        "name": "Energy Price",
        "group": "dashboard_group_main",
        "order": 1,
        "width": 4,
        "height": 4,
        "gtype": "gage",
        "title": "‚ö° Energy Price",
        "label": "‚Ç¨/kWh",
        "format": "{{value}}",
        "min": 0,
        "max": "0.4",
        "colors": ["#00b04f","#e6e600","#ca3838"],
        "seg1": "0.15",
        "seg2": "0.25",
        "className": "",
        "x": 800,
        "y": 80,
        "wires": []
    },
    {
        "id": "price_chart",
        "type": "ui_chart",
        "z": "dashboard_tab",
        "name": "Price Trend",
        "group": "dashboard_group_charts",
        "order": 1,
        "width": 12,
        "height": 6,
        "label": "‚ö° Energy Price Trend (24h)",
        "chartType": "line",
        "legend": "true",
        "xformat": "HH:mm",
        "interpolate": "linear",
        "nodata": "No data available",
        "dot": false,
        "ymin": "",
        "ymax": "",
        "removeOlder": 24,
        "removeOlderPoints": "",
        "removeOlderUnit": "3600",
        "cutout": 0,
        "useOneColor": false,
        "useUTC": false,
        "colors": ["#1f77b4","#aec7e8","#ff7f0e"],
        "outputs": 1,
        "x": 800,
        "y": 120,
        "wires": [[]]
    },
    {
        "id": "weather_query",
        "type": "function",
        "z": "dashboard_tab",
        "name": "Query Weather Data",
        "func": "// Query InfluxDB for latest weather data\nconst tempQuery = `\nfrom(bucket: \"chocolate_factory\")\n  |> range(start: -24h)\n  |> filter(fn: (r) => r._measurement == \"weather_data\")\n  |> filter(fn: (r) => r._field == \"temperature\")\n  |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)\n  |> yield(name: \"temperature\")\n`;\n\nconst humidityQuery = `\nfrom(bucket: \"chocolate_factory\")\n  |> range(start: -24h)\n  |> filter(fn: (r) => r._measurement == \"weather_data\")\n  |> filter(fn: (r) => r._field == \"humidity\")\n  |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)\n  |> yield(name: \"humidity\")\n`;\n\nmsg.tempQuery = tempQuery;\nmsg.humidityQuery = humidityQuery;\n\nreturn [msg, msg];",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 200,
        "y": 200,
        "wires": [["temp_influx"], ["humidity_influx"]]
    },
    {
        "id": "temp_influx",
        "type": "influxdb out",
        "z": "dashboard_tab",
        "influxdb": "influx_config",
        "name": "Temperature Query",
        "measurement": "",
        "precision": "",
        "retentionPolicy": "",
        "database": "",
        "precisionV18FluxV20": "ms",
        "retentionPolicyV18Flux": "",
        "writeType": "query",
        "x": 420,
        "y": 180,
        "wires": [["temp_gauge"]]
    },
    {
        "id": "humidity_influx", 
        "type": "influxdb out",
        "z": "dashboard_tab",
        "influxdb": "influx_config",
        "name": "Humidity Query",
        "measurement": "",
        "precision": "",
        "retentionPolicy": "",
        "database": "",
        "precisionV18FluxV20": "ms",
        "retentionPolicyV18Flux": "",
        "writeType": "query",
        "x": 420,
        "y": 220,
        "wires": [["humidity_gauge"]]
    },
    {
        "id": "temp_gauge",
        "type": "ui_gauge",
        "z": "dashboard_tab",
        "name": "Temperature",
        "group": "dashboard_group_main",
        "order": 2,
        "width": 4,
        "height": 4,
        "gtype": "gage",
        "title": "üå°Ô∏è Temperature",
        "label": "¬∞C",
        "format": "{{value}}",
        "min": 0,
        "max": 45,
        "colors": ["#00b04f","#e6e600","#ca3838"],
        "seg1": "20",
        "seg2": "30",
        "className": "",
        "x": 620,
        "y": 180,
        "wires": []
    },
    {
        "id": "humidity_gauge",
        "type": "ui_gauge", 
        "z": "dashboard_tab",
        "name": "Humidity",
        "group": "dashboard_group_main",
        "order": 3,
        "width": 4,
        "height": 4,
        "gtype": "gage",
        "title": "üíß Humidity",
        "label": "%",
        "format": "{{value}}",
        "min": 0,
        "max": 100,
        "colors": ["#ca3838","#00b04f","#ca3838"],
        "seg1": "40",
        "seg2": "70",
        "className": "",
        "x": 620,
        "y": 220,
        "wires": []
    },
    {
        "id": "ml_predictions_api",
        "type": "http request",
        "z": "dashboard_tab",
        "name": "Get ML Status",
        "method": "GET",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "http://fastapi-app:8000/models/status",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 200,
        "y": 320,
        "wires": [["process_ml_status"]]
    },
    {
        "id": "process_ml_status",
        "type": "function",
        "z": "dashboard_tab",
        "name": "Process ML Status",
        "func": "// Process ML models status from FastAPI\nif (msg.payload && msg.payload.models) {\n    const models = msg.payload.models;\n    \n    // Energy Optimization Model Status\n    if (models.energy_optimization) {\n        msg.energyModel = {\n            payload: {\n                status: models.energy_optimization.status,\n                r2_score: models.energy_optimization.last_r2_score,\n                features: models.energy_optimization.features\n            },\n            topic: \"energy_model\"\n        };\n    }\n    \n    // Production Classifier Status\n    if (models.production_classifier) {\n        msg.classifierModel = {\n            payload: {\n                status: models.production_classifier.status,\n                accuracy: models.production_classifier.last_accuracy,\n                classes: models.production_classifier.classes.length\n            },\n            topic: \"classifier_model\"\n        };\n    }\n    \n    // MLflow Connection Status\n    if (msg.payload.mlflow_connection) {\n        msg.mlflowStatus = {\n            payload: msg.payload.mlflow_connection.status,\n            topic: \"mlflow_status\"\n        };\n    }\n    \n    return [msg.energyModel, msg.classifierModel, msg.mlflowStatus];\n}\n\nreturn null;",
        "outputs": 3,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 420,
        "y": 320,
        "wires": [["ml_energy_text"], ["ml_classifier_text"], ["mlflow_status_text"]]
    },
    {
        "id": "ml_energy_text",
        "type": "ui_text",
        "z": "dashboard_tab",
        "group": "dashboard_group_ml",
        "order": 1,
        "width": 4,
        "height": 2,
        "name": "Energy Model",
        "label": "üîã Energy Optimization",
        "format": "Status: {{payload.status}}<br>R¬≤ Score: {{payload.r2_score}}<br>Features: {{payload.features}}",
        "layout": "row-spread",
        "className": "",
        "x": 640,
        "y": 300,
        "wires": []
    },
    {
        "id": "ml_classifier_text",
        "type": "ui_text",
        "z": "dashboard_tab",
        "group": "dashboard_group_ml",
        "order": 2,
        "width": 4,
        "height": 2,
        "name": "Classifier Model",
        "label": "üç´ Production Classifier",
        "format": "Status: {{payload.status}}<br>Accuracy: {{payload.accuracy}}<br>Classes: {{payload.classes}}",
        "layout": "row-spread",
        "className": "",
        "x": 650,
        "y": 330,
        "wires": []
    },
    {
        "id": "mlflow_status_text",
        "type": "ui_text",
        "z": "dashboard_tab",
        "group": "dashboard_group_ml",
        "order": 3,
        "width": 4,
        "height": 2,
        "name": "MLflow Status",
        "label": "üèóÔ∏è MLflow Server",
        "format": "Status: {{payload}}",
        "layout": "row-spread",
        "className": "",
        "x": 640,
        "y": 360,
        "wires": []
    },
    {
        "id": "production_prediction_api",
        "type": "http request",
        "z": "dashboard_tab",
        "name": "Get Production Prediction",
        "method": "POST",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "http://fastapi-app:8000/predict/production-recommendation",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [{"keyType":"Content-Type","valueType":"application/json"}],
        "x": 200,
        "y": 440,
        "wires": [["process_prediction"]]
    },
    {
        "id": "create_prediction_payload",
        "type": "function",
        "z": "dashboard_tab",
        "name": "Create Prediction Request",
        "func": "// Create prediction request with current conditions\n// This should get latest values from context or default values\nconst currentPrice = context.get('currentPrice') || 0.15;\nconst currentTemp = context.get('currentTemp') || 22;\nconst currentHumidity = context.get('currentHumidity') || 55;\n\nmsg.payload = {\n    price_eur_kwh: currentPrice,\n    temperature: currentTemp,\n    humidity: currentHumidity\n};\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 200,
        "y": 480,
        "wires": [["production_prediction_api"]]
    },
    {
        "id": "process_prediction",
        "type": "function",
        "z": "dashboard_tab",
        "name": "Process Prediction",
        "func": "// Process production prediction response\nif (msg.payload && msg.payload.prediction) {\n    const pred = msg.payload.prediction;\n    \n    msg.recommendation = {\n        payload: {\n            recommendation: pred.production_recommendation,\n            index: pred.chocolate_production_index,\n            urgency: pred.urgency,\n            description: pred.description\n        },\n        topic: \"production_recommendation\"\n    };\n    \n    // Set alert color based on urgency\n    let alertColor = \"green\";\n    if (pred.urgency === \"critical\") alertColor = \"red\";\n    else if (pred.urgency === \"high\") alertColor = \"orange\";\n    else if (pred.urgency === \"medium\") alertColor = \"yellow\";\n    \n    msg.alert = {\n        payload: `${pred.recommendation}: ${pred.description}`,\n        color: alertColor,\n        topic: \"production_alert\"\n    };\n    \n    return [msg.recommendation, msg.alert];\n}\n\nreturn null;",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 420,
        "y": 440,
        "wires": [["production_recommendation_text"], ["production_alert"]]
    },
    {
        "id": "production_recommendation_text",
        "type": "ui_text",
        "z": "dashboard_tab",
        "group": "dashboard_group_alerts",
        "order": 1,
        "width": 8,
        "height": 3,
        "name": "Production Recommendation",
        "label": "üç´ Current Recommendation",
        "format": "{{payload.recommendation}}<br>Index: {{payload.index}}<br>{{payload.description}}",
        "layout": "row-spread",
        "className": "",
        "x": 660,
        "y": 420,
        "wires": []
    },
    {
        "id": "production_alert",
        "type": "ui_text",
        "z": "dashboard_tab",
        "group": "dashboard_group_alerts",
        "order": 2,
        "width": 4,
        "height": 2,
        "name": "Alert Status",
        "label": "üö® Alert Level",
        "format": "<font color='{{color}}'>{{payload}}</font>",
        "layout": "row-spread",
        "className": "",
        "x": 640,
        "y": 460,
        "wires": []
    },
    {
        "id": "timer_5min",
        "type": "inject",
        "z": "dashboard_tab",
        "name": "Every 5 minutes",
        "props": [{"p":"payload"},{"p":"topic","vt":"str"}],
        "repeat": "300",
        "crontab": "",
        "once": true,
        "onceDelay": 0.1,
        "topic": "refresh",
        "payload": "",
        "payloadType": "date",
        "x": 50,
        "y": 100,
        "wires": [["influx_query_prices", "weather_query"]]
    },
    {
        "id": "timer_30sec",
        "type": "inject",
        "z": "dashboard_tab",
        "name": "Every 30 seconds",
        "props": [{"p":"payload"},{"p":"topic","vt":"str"}],
        "repeat": "30",
        "crontab": "",
        "once": true,
        "onceDelay": 0.5,
        "topic": "ml_refresh",
        "payload": "",
        "payloadType": "date",
        "x": 50,
        "y": 320,
        "wires": [["ml_predictions_api", "create_prediction_payload"]]
    },
    {
        "id": "influx_config",
        "type": "influxdb",
        "hostname": "influxdb",
        "port": "8086",
        "protocol": "http",
        "database": "chocolate_factory",
        "name": "InfluxDB Connection",
        "usetls": false,
        "tls": "",
        "influxdbVersion": "2.0",
        "url": "http://influxdb:8086",
        "rejectUnauthorized": false
    }
]
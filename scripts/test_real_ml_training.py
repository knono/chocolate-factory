#!/usr/bin/env python3
"""
Test Real ML Training
=====================
Tests the new train_models_hybrid() with real REE + SIAR data.

Run: python scripts/test_real_ml_training.py
"""

import asyncio
import sys
import logging
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src/fastapi-app"))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def main():
    """Run training test"""
    try:
        from services.direct_ml import DirectMLService

        print("\n" + "="*80)
        print("üî¨ TESTING REAL ML TRAINING WITH ACTUAL DATA")
        print("="*80 + "\n")

        # Initialize service
        ml_service = DirectMLService()

        # Run training
        print("Starting training...")
        results = await ml_service.train_models_hybrid()

        # Display results
        print("\n" + "="*80)
        print("üìä TRAINING RESULTS")
        print("="*80 + "\n")

        if results.get('success'):
            print("‚úÖ Training succeeded!\n")

            # Energy model
            if 'energy_model' in results:
                energy = results['energy_model']
                print("Energy Model (Regression):")
                print(f"  - R¬≤ Score: {energy.get('r2_score', 'N/A'):.4f}")
                print(f"  - Training samples: {energy.get('training_samples', 'N/A')}")
                print(f"  - Test samples: {energy.get('test_samples', 'N/A')}")
                print(f"  - Strategy: {energy.get('strategy', 'N/A')}")
                print(f"  - Model path: {energy.get('model_path', 'N/A')}")

            # Production model
            if 'production_model' in results:
                prod = results['production_model']
                print("\nProduction Model (Classification):")
                print(f"  - Accuracy: {prod.get('accuracy', 'N/A'):.4f}")
                print(f"  - Training samples: {prod.get('training_samples', 'N/A')}")
                print(f"  - Test samples: {prod.get('test_samples', 'N/A')}")
                print(f"  - Classes: {prod.get('classes', 'N/A')}")
                print(f"  - Strategy: {prod.get('strategy', 'N/A')}")
                print(f"  - Model path: {prod.get('model_path', 'N/A')}")

            # Summary
            print(f"\nTraining Summary:")
            print(f"  - Total merged samples: {results.get('total_samples', 'N/A')}")
            print(f"  - Training mode: {results.get('training_mode', 'N/A')}")
            print(f"  - Features used: {results.get('features_used', 'N/A')}")
            print(f"  - Timestamp: {results.get('timestamp', 'N/A')}")

            print("\n‚úîÔ∏è  TRAINING VALIDATION: REAL DATA, HONEST METRICS")
            print("‚úîÔ∏è  No data leakage (features ‚â† target)")
            print("‚úîÔ∏è  Proper train/test split on real data")

        else:
            print(f"‚ùå Training failed:")
            print(f"  Error: {results.get('error', 'Unknown error')}")

        print("\n" + "="*80 + "\n")

    except Exception as e:
        print(f"\n‚ùå Test failed with exception:")
        print(f"   {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
